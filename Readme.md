
# VisionMate AI ğŸŒ  

VisionMate AI is an innovative application designed to provide **AI-powered visual assistance**. This tool offers multiple features, including image analysis, object detection, text extraction, and text-to-speech capabilities, making it an accessible and user-friendly solution.  

---

## ğŸŒŸ Features  

- **Visual Insights**: Get detailed descriptions of uploaded images.  
- **Object Detection**: Identify and highlight objects in images.  
- **Text Reader**: Extract and display text from images.  
- **Accessibility Aid**: Convert extracted text to audio for better accessibility.  

---

## ğŸ› ï¸ Technologies Used  

- **Streamlit**: For building the interactive web application.  
- **Google Generative AI**: For enhanced AI capabilities.  
- **PyTorch**: Used for object detection with Faster R-CNN.  
- **Pytesseract**: For optical character recognition (OCR).  
- **gTTS & PyGame**: To convert text to speech and play audio.  

---

## ğŸš€ Getting Started  

### Prerequisites  
Ensure you have the following installed:  
- Python 3.8+  
- pip (Python package manager)  
- Necessary libraries (see below)  

### Installation  

1. Clone the repository:  
   ```bash  
   git clone https://github.com/yourusername/VisionMateAI.git  
   cd VisionMateAI  
   ```  

2. Install the required libraries:  
   ```bash  
   pip install -r requirements.txt  
   ```  

3. Add your **Google Generative AI API key** in the code:  
   Replace `"Your API Key here"` in the file with your actual API key.  

4. Run the app:  
   ```bash  
   streamlit run FINAL_PROJECT.py  
   ```  

---

## ğŸ–¼ï¸ Usage  

1. Upload an image file (JPEG, JPG, or PNG).  
2. Use the buttons provided to:  
   - **Analyze Image** for scene insights.  
   - **Extract Text** to read and display text.  
   - **Play Narration** for audio output of extracted text.  
3. Stop audio using the "Stop Audio" button.  

---

## ğŸ¤ Acknowledgments  

- **Innomatics Research Labs**: For their mentorship and guidance during the project.  
- Open-source libraries and frameworks that made this possible.  

---

## ğŸ“œ License  

This project is licensed under the [MIT License](LICENSE).  

---  

## ğŸ”— Connect  

Feel free to share feedback or contribute to the project by opening issues or pull requests!  
